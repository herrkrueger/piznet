#!/usr/bin/env python3
"""
Complete Pipeline Integration Test for Patent Analysis Platform
Enhanced from EPO PATLIB 2025 Live Demo Code

This script tests the complete workflow:
Search ‚Üí Applicant Analysis ‚Üí Classification Analysis ‚Üí Citation Analysis ‚Üí Geographic Analysis

Usage:
    python processors/test_complete_pipeline.py
    python -m processors.test_complete_pipeline
    ./processors/test_complete_pipeline.py
"""

import sys
import os
from pathlib import Path
import logging
import pandas as pd
import time
from typing import Dict, Any, List, Optional
import json

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

def setup_logging():
    """Setup test logging configuration."""
    logging.basicConfig(
        level=logging.INFO,
        format='%(levelname)s: %(message)s',
        handlers=[logging.StreamHandler()]
    )
    return logging.getLogger(__name__)

def print_section(title: str, char: str = '=', width: int = 70):
    """Print a formatted section header."""
    print(f'\n{title}')
    print(char * width)

def print_subsection(title: str):
    """Print a formatted subsection header."""
    print(f'\n{title}')
    print('-' * 50)

def test_complete_workflow():
    """Test the complete patent analysis workflow."""
    print_section('üöÄ Complete Pipeline Workflow Test')
    
    try:
        # Step 1: Import all processors
        print_subsection('Step 1: Import All Processors')
        from processors import (
            create_patent_search_processor,
            create_applicant_analyzer,
            create_classification_analyzer, 
            create_citation_analyzer,
            create_geographic_analyzer
        )
        print('   ‚úÖ All processors imported successfully')
        
        # Step 2: Initialize all processors
        print_subsection('Step 2: Initialize All Processors')
        
        # Initialize search processor (foundation)
        search_processor = create_patent_search_processor()
        print('   ‚úÖ PatentSearchProcessor initialized')
        
        # Initialize enhancement processors
        applicant_analyzer = create_applicant_analyzer()
        print('   ‚úÖ ApplicantAnalyzer initialized')
        
        classification_analyzer = create_classification_analyzer()
        print('   ‚úÖ ClassificationAnalyzer initialized')
        
        citation_analyzer = create_citation_analyzer()
        print('   ‚úÖ CitationAnalyzer initialized')
        
        geographic_analyzer = create_geographic_analyzer()
        print('   ‚úÖ GeographicAnalyzer initialized')
        
        # Step 3: Create mock search results (simulating real PATSTAT data)
        print_subsection('Step 3: Create Mock Search Results')
        mock_search_results = pd.DataFrame({
            'docdb_family_id': [12345, 23456, 34567, 45678, 56789],
            'quality_score': [3, 2, 3, 1, 2],
            'match_type': ['intersection', 'keyword', 'intersection', 'classification', 'keyword'],
            'earliest_filing_year': [2020, 2019, 2021, 2018, 2022],
            'family_size': [5, 3, 7, 2, 4],
            'primary_technology': ['C22B', 'H01M', 'C22B', 'C04B', 'H01M'],
            'keyword_matches': [['rare earth', 'extraction'], ['battery'], ['cerium'], ['ceramic'], ['lithium']]
        })
        print(f'   ‚úÖ Mock search results created: {len(mock_search_results)} families')
        print(f'   üìä Quality distribution: {mock_search_results["quality_score"].value_counts().to_dict()}')
        
        # Step 4: Test Applicant Analysis
        print_subsection('Step 4: Test Applicant Analysis')
        start_time = time.time()
        
        try:
            applicant_results = applicant_analyzer.analyze_search_results(mock_search_results)
            applicant_time = time.time() - start_time
            print(f'   ‚úÖ Applicant analysis completed in {applicant_time:.3f}s')
            print(f'   üìä Applicant results: {len(applicant_results)} records')
            
            # Check for required columns
            expected_cols = ['applicant_name', 'patent_families', 'strategic_score']
            missing_cols = [col for col in expected_cols if col not in applicant_results.columns]
            if missing_cols:
                print(f'   ‚ö†Ô∏è Missing columns: {missing_cols}')
            else:
                print('   ‚úÖ All expected columns present')
                
        except Exception as e:
            print(f'   ‚ùå Applicant analysis failed: {e}')
            return False
        
        # Step 5: Test Classification Analysis
        print_subsection('Step 5: Test Classification Analysis')
        start_time = time.time()
        
        try:
            classification_results = classification_analyzer.analyze_search_results(mock_search_results)
            classification_time = time.time() - start_time
            print(f'   ‚úÖ Classification analysis completed in {classification_time:.3f}s')
            print(f'   üìä Classification results: {len(classification_results)} records')
            
            # Check that we have some meaningful results
            if len(classification_results.columns) > 0:
                print(f'   ‚úÖ Classification data available with {len(classification_results.columns)} attributes')
            else:
                print('   ‚ö†Ô∏è No classification data attributes found')
                
        except Exception as e:
            print(f'   ‚ùå Classification analysis failed: {e}')
            return False
        
        # Step 6: Test Citation Analysis
        print_subsection('Step 6: Test Citation Analysis')
        start_time = time.time()
        
        try:
            citation_results = citation_analyzer.analyze_search_results(mock_search_results)
            citation_time = time.time() - start_time
            print(f'   ‚úÖ Citation analysis completed in {citation_time:.3f}s')
            print(f'   üìä Citation results: {len(citation_results)} records')
            
            # Check that we have some meaningful results
            if len(citation_results.columns) > 0:
                print(f'   ‚úÖ Citation data available with {len(citation_results.columns)} attributes')
            else:
                print('   ‚ö†Ô∏è No citation data found (expected with mock data)')
                
        except Exception as e:
            print(f'   ‚ùå Citation analysis failed: {e}')
            return False
        
        # Step 7: Test Enhanced Geographic Analysis with NUTS and Inventor Support
        print_subsection('Step 7: Test Enhanced Geographic Analysis')
        start_time = time.time()
        
        try:
            # Test standard geographic analysis (applicants by default)
            print('   Testing standard geographic analysis...')
            geographic_results = geographic_analyzer.analyze_search_results(mock_search_results)
            print(f'   ‚úÖ Standard analysis: {len(geographic_results)} records')
            
            # Test applicant-specific analysis
            print('   Testing applicant-specific analysis...')
            applicant_geo_results = geographic_analyzer.analyze_search_results(
                mock_search_results, 
                analyze_applicants=True, 
                analyze_inventors=False,
                nuts_level=3
            )
            print(f'   ‚úÖ Applicant geography: {len(applicant_geo_results)} records')
            
            # Test inventor-specific analysis
            print('   Testing inventor-specific analysis...')
            inventor_geo_results = geographic_analyzer.analyze_search_results(
                mock_search_results,
                analyze_applicants=False,
                analyze_inventors=True,
                nuts_level=3
            )
            print(f'   ‚úÖ Inventor geography: {len(inventor_geo_results)} records')
            
            # Test combined analysis with different NUTS levels
            print('   Testing NUTS level variations...')
            nuts1_results = geographic_analyzer.analyze_search_results(
                mock_search_results, analyze_applicants=True, analyze_inventors=True, nuts_level=1
            )
            nuts2_results = geographic_analyzer.analyze_search_results(
                mock_search_results, analyze_applicants=True, analyze_inventors=True, nuts_level=2
            )
            nuts3_results = geographic_analyzer.analyze_search_results(
                mock_search_results, analyze_applicants=True, analyze_inventors=True, nuts_level=3
            )
            print(f'   ‚úÖ NUTS level 1: {len(nuts1_results)} records')
            print(f'   ‚úÖ NUTS level 2: {len(nuts2_results)} records')
            print(f'   ‚úÖ NUTS level 3: {len(nuts3_results)} records')
            
            # Test specialized geographic methods
            print('   Testing specialized geographic methods...')
            try:
                specialized_inventor = geographic_analyzer.analyze_inventor_geography(mock_search_results, nuts_level=2)
                print(f'   ‚úÖ Specialized inventor method: {len(specialized_inventor)} records')
            except Exception as e:
                print(f'   ‚ö†Ô∏è Specialized inventor method: {e}')
            
            try:
                specialized_applicant = geographic_analyzer.analyze_applicant_geography(mock_search_results, nuts_level=2)
                print(f'   ‚úÖ Specialized applicant method: {len(specialized_applicant)} records')
            except Exception as e:
                print(f'   ‚ö†Ô∏è Specialized applicant method: {e}')
            
            try:
                geo_comparison = geographic_analyzer.compare_innovation_vs_filing_geography(mock_search_results, nuts_level=2)
                print(f'   ‚úÖ Geographic comparison: {len(geo_comparison)} analysis keys')
            except Exception as e:
                print(f'   ‚ö†Ô∏è Geographic comparison: {e}')
            
            geographic_time = time.time() - start_time
            print(f'   ‚úÖ Enhanced geographic analysis completed in {geographic_time:.3f}s')
            
            # Check NUTS mapper integration
            if hasattr(geographic_analyzer, 'nuts_mapper') and geographic_analyzer.nuts_mapper:
                print('   ‚úÖ NUTS mapper integrated successfully')
            else:
                print('   ‚ö†Ô∏è NUTS mapper not available (fallback mode)')
            
            # Check country mapper integration
            if hasattr(geographic_analyzer, 'country_mapper') and geographic_analyzer.country_mapper:
                print('   ‚úÖ Country mapper integrated successfully')
            else:
                print('   ‚ö†Ô∏è Country mapper not available (fallback mode)')
            
        except Exception as e:
            print(f'   ‚ùå Enhanced geographic analysis failed: {e}')
            import traceback
            traceback.print_exc()
            return False
        
        # Step 8: Test Data Integration
        print_subsection('Step 8: Test Data Integration')
        
        try:
            # Merge all results back to original search results
            integrated_data = mock_search_results.copy()
            
            # Merge applicant data (note: applicant results are aggregated by applicant, not by family)
            if not applicant_results.empty:
                print('   ‚úÖ Applicant data available (aggregated by applicant)')
                # Note: Applicant data is aggregated by applicant_name, not by docdb_family_id
                # so direct merge is not possible - this is expected behavior
            
            # Check data availability (these processors may return aggregated data)
            if not classification_results.empty:
                print('   ‚úÖ Classification data available (aggregated by technology domain)')
            else:
                print('   üìù No classification data (expected with limited mock data)')
            
            # Check citation data 
            if not citation_results.empty:
                print('   ‚úÖ Citation data available')
            else:
                print('   üìù No citation data (expected with mock family IDs)')
            
            # Check geographic data
            if not geographic_results.empty:
                print('   ‚úÖ Geographic data available')
            else:
                print('   üìù No geographic data (expected with mock family IDs)')
            
            print(f'   üìä Final integrated dataset: {len(integrated_data)} families with {len(integrated_data.columns)} attributes')
            
            # Check data completeness
            null_counts = integrated_data.isnull().sum()
            if null_counts.any():
                print(f'   ‚ö†Ô∏è Some null values found: {null_counts[null_counts > 0].to_dict()}')
            else:
                print('   ‚úÖ No missing values in integrated dataset')
                
        except Exception as e:
            print(f'   ‚ùå Data integration failed: {e}')
            return False
        
        # Step 9: Performance Summary
        print_subsection('Step 9: Performance Summary')
        total_time = applicant_time + classification_time + citation_time + geographic_time
        print(f'   ‚è±Ô∏è Total processing time: {total_time:.3f}s')
        print(f'   üìä Average time per family: {total_time/len(mock_search_results):.3f}s')
        print(f'   üöÄ Processing rate: {len(mock_search_results)/total_time:.1f} families/second')
        
        # Step 10: Generate Summary Report
        print_subsection('Step 10: Generate Summary Report')
        
        summary_report = {
            'pipeline_status': 'SUCCESS',
            'families_processed': len(mock_search_results),
            'processing_time': total_time,
            'components_tested': {
                'search_processor': True,
                'applicant_analyzer': True,
                'classification_analyzer': True,
                'citation_analyzer': True,
                'geographic_analyzer': True
            },
            'data_quality': {
                'families_with_complete_data': len(integrated_data.dropna()),
                'total_attributes': len(integrated_data.columns),
                'integration_success': True
            },
            'performance_metrics': {
                'families_per_second': len(mock_search_results)/total_time,
                'average_time_per_family': total_time/len(mock_search_results)
            }
        }
        
        print('   ‚úÖ Summary report generated')
        print(f'   üìä Pipeline status: {summary_report["pipeline_status"]}')
        print(f'   üìä Families processed: {summary_report["families_processed"]}')
        print(f'   üìä Integration success: {summary_report["data_quality"]["integration_success"]}')
        
        return True, summary_report
        
    except Exception as e:
        print(f'‚ùå Complete workflow test failed: {e}')
        import traceback
        traceback.print_exc()
        return False, None

def test_nuts_geographic_integration():
    """Test NUTS geographic integration specifically."""
    print_section('üá™üá∫ NUTS Geographic Integration Test')
    
    try:
        print_subsection('Data Access Integration Check')
        
        # Check if data access modules are available
        try:
            from data_access.nuts_mapper import create_nuts_mapper
            from data_access.country_mapper import create_country_mapper
            print('   ‚úÖ Data access mappers available')
        except ImportError as e:
            print(f'   ‚ö†Ô∏è Data access mappers not available: {e}')
            return False
        
        # Test NUTS mapper creation
        print_subsection('NUTS Mapper Testing')
        try:
            nuts_mapper = create_nuts_mapper()
            print('   ‚úÖ NUTS mapper created successfully')
            
            # Test basic NUTS operations
            test_codes = ['DE111', 'FR101', 'IT123', 'ES111']
            for code in test_codes:
                info = nuts_mapper.get_nuts_info(code)
                hierarchy = nuts_mapper.get_nuts_hierarchy(code)
                print(f'   üìç {code}: {info.get("nuts_label", "Unknown")} (Level {info.get("nuts_level", "?")})')
                print(f'     Hierarchy: {" ‚Üí ".join(hierarchy) if hierarchy else "None"}')
            
        except Exception as e:
            print(f'   ‚ùå NUTS mapper testing failed: {e}')
            return False
        
        # Test geographic processor with NUTS integration
        print_subsection('Geographic Processor NUTS Integration')
        try:
            from processors import create_geographic_analyzer
            analyzer = create_geographic_analyzer()
            
            # Check if NUTS mapper is properly integrated
            if hasattr(analyzer, 'nuts_mapper') and analyzer.nuts_mapper:
                print('   ‚úÖ NUTS mapper properly integrated into geographic processor')
                
                # Test NUTS helper methods
                if hasattr(analyzer, '_get_nuts_info'):
                    nuts_info = analyzer._get_nuts_info('DE111')
                    print(f'   ‚úÖ NUTS info method works: {nuts_info.get("nuts_code", "Unknown")}')
                
                if hasattr(analyzer, '_get_target_nuts_from_hierarchy'):
                    target = analyzer._get_target_nuts_from_hierarchy(['DE', 'DE1', 'DE11', 'DE111'], 2)
                    print(f'   ‚úÖ NUTS hierarchy method works: {target}')
                
            else:
                print('   ‚ö†Ô∏è NUTS mapper not integrated into geographic processor')
                return False
                
        except Exception as e:
            print(f'   ‚ùå Geographic processor NUTS integration failed: {e}')
            return False
        
        # Test role-based analysis parameters
        print_subsection('Role-Based Analysis Testing')
        try:
            mock_data = pd.DataFrame({
                'docdb_family_id': [12345, 23456],
                'quality_score': [3, 2],
                'earliest_filing_year': [2020, 2019]
            })
            
            # Test different role combinations
            role_tests = [
                ('Applicants only', True, False),
                ('Inventors only', False, True),
                ('Both roles', True, True)
            ]
            
            for test_name, analyze_applicants, analyze_inventors in role_tests:
                try:
                    result = analyzer.analyze_search_results(
                        mock_data, 
                        analyze_applicants=analyze_applicants,
                        analyze_inventors=analyze_inventors,
                        nuts_level=3
                    )
                    print(f'   ‚úÖ {test_name}: {len(result)} records (expected: 0 with mock data)')
                except Exception as e:
                    print(f'   ‚ùå {test_name} failed: {e}')
                    return False
            
        except Exception as e:
            print(f'   ‚ùå Role-based analysis testing failed: {e}')
            return False
        
        print_subsection('NUTS Integration Summary')
        print('   ‚úÖ NUTS mapper creation: PASS')
        print('   ‚úÖ Geographic processor integration: PASS') 
        print('   ‚úÖ Role-based analysis: PASS')
        print('   ‚úÖ NUTS hierarchy navigation: PASS')
        print('   üá™üá∫ NUTS integration ready for EPO PATLIB 2025 demonstration')
        
        return True
        
    except Exception as e:
        print(f'‚ùå NUTS geographic integration test failed: {e}')
        import traceback
        traceback.print_exc()
        return False

def test_real_patstat_readiness():
    """Test readiness for real PATSTAT integration."""
    print_section('üóÑÔ∏è Real PATSTAT Integration Readiness')
    
    try:
        # Check PATSTAT availability
        print_subsection('PATSTAT Availability Check')
        
        try:
            from epo.tipdata.patstat import PatstatClient
            print('   ‚úÖ PATSTAT client available')
            
            # Test PROD environment connection
            try:
                client = PatstatClient(env='PROD')
                session = client.orm()
                print('   ‚úÖ PROD environment connection successful')
                
                # Test basic table access
                from epo.tipdata.patstat.database.models import TLS201_APPLN
                test_query = session.query(TLS201_APPLN.docdb_family_id).limit(1)
                result = test_query.first()
                
                if result:
                    print('   ‚úÖ Database table access confirmed')
                    print('   üöÄ Ready for real patent family searches!')
                else:
                    print('   ‚ö†Ô∏è Database tables accessible but no data returned')
                    
            except Exception as e:
                print(f'   ‚ö†Ô∏è PROD connection issue: {e}')
                print('   üìù This may be expected in testing environment')
                
        except ImportError:
            print('   ‚ö†Ô∏è PATSTAT not available (testing mode)')
            print('   üìù Pipeline works with mock data and will integrate with PATSTAT when available')
        
        # Check processor PATSTAT readiness
        print_subsection('Processor PATSTAT Integration Status')
        
        from processors import (
            create_patent_search_processor,
            create_applicant_analyzer,
            create_classification_analyzer,
            create_citation_analyzer,
            create_geographic_analyzer
        )
        
        processors = [
            ('Search Processor', create_patent_search_processor),
            ('Applicant Analyzer', create_applicant_analyzer),
            ('Classification Analyzer', create_classification_analyzer),
            ('Citation Analyzer', create_citation_analyzer),
            ('Geographic Analyzer', create_geographic_analyzer)
        ]
        
        for name, create_func in processors:
            try:
                processor = create_func()
                if hasattr(processor, 'patstat_client') and processor.patstat_client:
                    print(f'   ‚úÖ {name}: PATSTAT client initialized')
                elif hasattr(processor, 'session') and processor.session:
                    print(f'   ‚úÖ {name}: PATSTAT session available')
                else:
                    print(f'   üìù {name}: Ready for PATSTAT integration')
            except Exception as e:
                print(f'   ‚ö†Ô∏è {name}: Integration issue - {e}')
        
        return True
        
    except Exception as e:
        print(f'‚ùå PATSTAT readiness test failed: {e}')
        return False

def test_scaling_capabilities():
    """Test pipeline scaling capabilities."""
    print_section('üìà Pipeline Scaling Test')
    
    try:
        print_subsection('Scaling Test with Larger Dataset')
        
        from processors import (
            create_applicant_analyzer,
            create_classification_analyzer,
            create_citation_analyzer,
            create_geographic_analyzer
        )
        
        # Create larger mock dataset
        import numpy as np
        
        family_ids = range(10000, 11000)  # 1000 families
        large_mock_results = pd.DataFrame({
            'docdb_family_id': family_ids,
            'quality_score': np.random.choice([1, 2, 3], size=len(family_ids)),
            'match_type': np.random.choice(['keyword', 'classification', 'intersection'], size=len(family_ids)),
            'earliest_filing_year': np.random.choice(range(2010, 2025), size=len(family_ids)),
            'family_size': np.random.choice(range(1, 20), size=len(family_ids)),
            'primary_technology': np.random.choice(['C22B', 'H01M', 'C04B', 'C09K'], size=len(family_ids))
        })
        
        print(f'   üìä Large dataset created: {len(large_mock_results)} families')
        
        # Test each processor with larger dataset
        processors = [
            ('Applicant Analyzer', create_applicant_analyzer()),
            ('Classification Analyzer', create_classification_analyzer()),
            ('Citation Analyzer', create_citation_analyzer()),
            ('Geographic Analyzer', create_geographic_analyzer()),
            ('Geographic Analyzer (NUTS)', create_geographic_analyzer())
        ]
        
        scaling_results = {}
        
        for name, processor in processors:
            start_time = time.time()
            try:
                result = processor.analyze_search_results(large_mock_results)
                processing_time = time.time() - start_time
                rate = len(large_mock_results) / processing_time
                
                scaling_results[name] = {
                    'success': True,
                    'time': processing_time,
                    'rate': rate,
                    'records_processed': len(result)
                }
                
                print(f'   ‚úÖ {name}: {processing_time:.2f}s ({rate:.1f} families/sec)')
                
            except Exception as e:
                scaling_results[name] = {
                    'success': False,
                    'error': str(e)
                }
                print(f'   ‚ùå {name}: Failed - {e}')
        
        # Performance analysis
        print_subsection('Performance Analysis')
        successful_processors = [k for k, v in scaling_results.items() if v.get('success', False)]
        
        if successful_processors:
            avg_rate = np.mean([scaling_results[p]['rate'] for p in successful_processors])
            print(f'   üìä Average processing rate: {avg_rate:.1f} families/second')
            print(f'   üìä Estimated capacity: {avg_rate * 3600:.0f} families/hour')
            
            if avg_rate > 100:
                print('   üöÄ Excellent performance for production use')
            elif avg_rate > 50:
                print('   ‚úÖ Good performance for most use cases')
            else:
                print('   ‚ö†Ô∏è Performance may need optimization for large datasets')
        
        return True, scaling_results
        
    except Exception as e:
        print(f'‚ùå Scaling test failed: {e}')
        return False, None

def generate_final_report(workflow_success: bool, workflow_report: Optional[Dict], 
                         patstat_ready: bool, nuts_integration_success: bool,
                         scaling_success: bool, scaling_results: Optional[Dict]) -> str:
    """Generate comprehensive final report."""
    print_section('üìã Complete Pipeline Test Report', '=', 70)
    
    # Overall status
    overall_success = workflow_success and patstat_ready and nuts_integration_success and scaling_success
    status = "SUCCESS" if overall_success else "PARTIAL SUCCESS"
    
    print(f'Pipeline Status: {status}')
    print(f'=' * 70)
    
    # Component status
    print('\nComponent Test Results:')
    print(f'   ‚úÖ Complete Workflow: {"PASS" if workflow_success else "FAIL"}')
    print(f'   ‚úÖ PATSTAT Readiness: {"PASS" if patstat_ready else "FAIL"}')
    print(f'   üá™üá∫ NUTS Integration: {"PASS" if nuts_integration_success else "FAIL"}')
    print(f'   ‚úÖ Scaling Capability: {"PASS" if scaling_success else "FAIL"}')
    
    # Detailed workflow results
    if workflow_report:
        print('\nWorkflow Performance:')
        print(f'   üìä Families Processed: {workflow_report["families_processed"]}')
        print(f'   ‚è±Ô∏è Total Processing Time: {workflow_report["processing_time"]:.3f}s')
        print(f'   üöÄ Processing Rate: {workflow_report["performance_metrics"]["families_per_second"]:.1f} families/sec')
    
    # Scaling results
    if scaling_results:
        print('\nScaling Test Results:')
        for processor, result in scaling_results.items():
            if result.get('success'):
                print(f'   ‚úÖ {processor}: {result["rate"]:.1f} families/sec')
            else:
                print(f'   ‚ùå {processor}: {result.get("error", "Unknown error")}')
    
    # Final recommendations
    print('\nRecommendations:')
    if overall_success:
        print('   üéâ Pipeline is ready for production use!')
        print('   üöÄ All processors working correctly with search results')
        print('   üìä Performance is suitable for real-world patent analysis')
        print('   üóÑÔ∏è Ready for PATSTAT integration with live data')
    else:
        print('   üîç Review failed components above')
        print('   üìù Address any performance or integration issues')
        print('   üîÑ Re-run tests after fixes')
    
    # Next steps
    print('\nNext Steps:')
    print('   1. üóÑÔ∏è Test with real PATSTAT data (small batch)')
    print('   2. üìä Validate results with known patent datasets')
    print('   3. üöÄ Deploy to EPO PATLIB 2025 demo environment')
    print('   4. üìà Monitor performance with full-scale searches')
    
    return status

def main():
    """Main test execution function."""
    logger = setup_logging()
    
    print('üöÄ Complete Patent Analysis Pipeline - Integration Test')
    print('Enhanced from EPO PATLIB 2025 Live Demo Code')
    print('=' * 70)
    print('Testing: Search ‚Üí Applicant ‚Üí Classification ‚Üí Citation ‚Üí Geographic')
    
    try:
        # Execute complete workflow test
        workflow_success, workflow_report = test_complete_workflow()
        
        # Test PATSTAT readiness
        patstat_ready = test_real_patstat_readiness()
        
        # Test NUTS geographic integration
        nuts_integration_success = test_nuts_geographic_integration()
        
        # Test scaling capabilities
        scaling_success, scaling_results = test_scaling_capabilities()
        
        # Generate final comprehensive report
        final_status = generate_final_report(
            workflow_success, workflow_report, 
            patstat_ready, nuts_integration_success, scaling_success, scaling_results
        )
        
        return 0 if final_status == "SUCCESS" else 1
        
    except KeyboardInterrupt:
        print('\n‚ö†Ô∏è Test execution interrupted by user')
        return 1
    except Exception as e:
        print(f'\n‚ùå Test execution failed: {e}')
        import traceback
        traceback.print_exc()
        return 1

if __name__ == '__main__':
    exit_code = main()
    sys.exit(exit_code)